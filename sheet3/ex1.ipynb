{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mystate():\n",
    "    def __init__(self,pos1,pos2,reward):\n",
    "        self.pos1=pos1\n",
    "        self.pos2=pos2\n",
    "        self.reward=reward\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "\n",
    "    def __init__(self,size: int = 5,special_states: dict ={}, terminal_states: dict ={}):\n",
    "        self.size = size\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "        self.special_states=special_states\n",
    "        self.terminal_states=special_states\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"agent\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([1, 0]),  # right\n",
    "            1: np.array([0, 1]),  # up\n",
    "            2: np.array([-1, 0]),  # left\n",
    "            3: np.array([0, -1]),  # down\n",
    "        }\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location}\n",
    "\n",
    "    def _get_info(self):\n",
    "        distance_dict={}\n",
    "\n",
    "        for special_state_name, special_state in self.special_states.items():\n",
    "            distance_dict[special_state_name]= np.linalg.norm(self._agent_location - special_state.pos1,ord=1)\n",
    "        return distance_dict\n",
    "\n",
    "\n",
    "    def reset(self, seed = None, options = None):\n",
    "\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        action=int(action)\n",
    "        direction = self._action_to_direction[action]\n",
    "        in_special_state=False\n",
    "\n",
    "        for name, state in self.special_states.items():\n",
    "                if np.array_equal(self._agent_location, state.pos1):\n",
    "                    reward=state.reward\n",
    "                    self._agent_location=state.pos2\n",
    "                    in_special_state=True\n",
    "                    break\n",
    "        if not in_special_state:\n",
    "            agent_location_new = np.clip(\n",
    "                self._agent_location + direction, 0, self.size - 1\n",
    "            )\n",
    "            if np.array_equal(self._agent_location,agent_location_new):\n",
    "                    reward=-1\n",
    "            else:\n",
    "                    reward=0\n",
    "            self._agent_location=agent_location_new\n",
    "\n",
    "        terminated=False\n",
    "        truncated=False\n",
    "        obs=self._get_obs()\n",
    "        info=self._get_info()\n",
    "        return  obs, reward, terminated, truncated, info\n",
    "    \n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"\n",
    "        Visualisiert den aktuellen Zustand der Umgebung.\n",
    "        Wenn mode='human', wird der Zustand in der Konsole als Text ausgegeben.\n",
    "        \"\"\"\n",
    "        # Erstelle ein leeres Grid mit 'O'\n",
    "        grid = [[\"O\" for _ in range(self.size)] for _ in range(self.size)]\n",
    "\n",
    "        # Positioniere den Agenten im Grid\n",
    "        x, y = self._agent_location\n",
    "        \n",
    "\n",
    "        for name, state in self.special_states.items():\n",
    "             i1,i2=state.pos1\n",
    "             grid[i1][i2]=name\n",
    "\n",
    "        # Gebe das Grid in der Konsole aus\n",
    "        print(\"\\n\".join([\" \".join(row) for row in grid]))\n",
    "        print(\"\\n\")  # Leerzeile f√ºr bessere Lesbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.register(\n",
    "    id=\"gymnasium_env/GridWorld-v10\",\n",
    "    entry_point=GridWorldEnv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_states={'A': mystate(np.array([0,1]),np.array([4,1]),10), 'B': mystate(np.array([0,3]),np.array([2,3]),5)}\n",
    "env = gym.make(\"gymnasium_env/GridWorld-v10\", size=5,special_states=special_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(pi)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_length=1000\n",
    "env.reset()\n",
    "\n",
    "for i in range(eps_length):\n",
    "    action=env.action_space.sample()\n",
    "    a = env.step(action)\n",
    "    env.render()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
